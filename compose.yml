name: local-ai

services:
  app:
    image: localai/localai:latest-gpu-nvidia-cuda-13
    restart: unless-stopped
    extra_hosts: ["host.docker.internal:host-gateway"]
    # environment:
    #   DEBUG: true
    ports:
      - $APP_PORT:8080
    volumes:
      - ./data:/models
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
